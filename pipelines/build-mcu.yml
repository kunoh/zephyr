variables:
  major: 0
  minor: 1
  patch: 0
  normalizedBranchName: ${{ replace(replace(replace(variables['Build.SourceBranch'], 'refs/heads/', ''), '_', '-'), '/', '-') }}
  buildCounter: $[counter(variables['Build.SourceBranch'], 0)]
  isReleaseBranch: $[startsWith(variables['Build.SourceBranch'], 'refs/heads/release/')]
  versionSuffix: -$(normalizedBranchName).$(buildCounter)
  version: '$(major).$(minor).$(patch)$(versionSuffix)'

trigger:
  branches:
    include:
      - master

pool:
  name: 'Embedded'
  demands: TM_CAP_YOCTO_BUILD -equals 1

stages:
  - stage: clang_format
    displayName: Check formatting of code
    pool:
      name: 'Embedded'
      demands: TM_CAP_YOCTO_BUILD -equals 1

    jobs:
      - job: Check_clang_format
        timeoutInMinutes: 360
        container:
          image: tmesw.azurecr.io/mcu-builder:latest
          endpoint: tmesw-container-registry

        steps:
        - checkout: self
          clean: false
          persistCredentials: true

        - script: |
            git clean -fxd mcu-project/apps mcu-project/modules
            if [[ `git status --porcelain mcu-project/apps mcu-project/modules` ]]; then
              git status
              echo "##vso[task.logissue type=error]apps/ or modules/ is not clean after checkout."
              exit 1
            fi

            if ! ./build.py --format; then
              exit 1
            fi
            if [[ `git status --porcelain mcu-project/apps mcu-project/modules` ]]; then
              git status
              git diff
              echo "##vso[task.logissue type=error]C/C++ code in apps/ or modules/ is not correctly formatted. Run 'build.py --format'."
              exit 1
            fi
          displayName: Check formatting of code

  - stage: west_init
    displayName: Initialize west
    dependsOn: clang_format
    pool:
      name: 'Embedded'
      demands: TM_CAP_YOCTO_BUILD -equals 1

    jobs:
      - job: Init_Zephyr
        timeoutInMinutes: 360
        container:
          image: tmesw.azurecr.io/mcu-builder:latest
          endpoint: tmesw-container-registry

        steps:
        - checkout: self
          clean: false
          persistCredentials: true

        - template: set-version.yml
        - script: |
            rm -rf build
            unset ZEPHYR_BASE
            echo "Updating Zephyr repositories"
            if ! ./build.py --update; then
                # Sometimes git lock files remain if a job was stopped. Make a clean update in that case
                rm -rf zephyrproject
                ./build.py --update
            fi
            if [[ "$ZEPHYR_REQUIREMENTS" != "$(yq -r .manifest.projects[0].revision mcu-project/west.yml)" ]]; then
                echo "Updating python requirements"
                pip3 install --user -r zephyrproject/zephyr/scripts/requirements.txt
            fi

            # Compiling to native posix using cpp20 is failing when using GCC >= 11.
            # The Linux libstdc++ included in the host GCC 11 now directly makes use of the Linux futex for the atomics
            # If the symbol `_GLIBCXX_HAVE_LINUX_FUTEX` is not defined, libstdc++ will fall back to using an ordinary mutex.
            # Create a parallel c++config.h which undef the symbol
            cp -r files/bits zephyrproject/zephyr/boards/posix/native_posix
          displayName: Initialize Zephyr environment

  - stage: ztest
    displayName: Unit tests
    dependsOn: west_init
    pool:
      name: 'Embedded'
      demands: TM_CAP_YOCTO_BUILD -equals 1

    jobs:
      - job: run_unit_tests
        timeoutInMinutes: 360
        container:
          image: tmesw.azurecr.io/mcu-builder:latest
          endpoint: tmesw-container-registry

        steps:
        - checkout: self
          clean: false
          persistCredentials: true

        - script: |
            pack_logs () {
              tar -czf "$(Build.ArtifactStagingDirectory)/unit_tests_$(System.JobId).tar.gz" -C build/unit_tests .
              rm -rf build/unit_tests
            }
            unset ZEPHYR_BASE
            if [[ "$ZEPHYR_REQUIREMENTS" != "$(yq -r .manifest.projects[0].revision mcu-project/west.yml)" ]]; then
                echo "Updating Zephyr python requirements"
                pip3 install --user -r zephyrproject/zephyr/scripts/requirements.txt
            fi

            ./build.py --test

            # Validate that all test passed by looking at the twister output file.
            # Twister is not returning any exit codes on failures, therefore we will manual scan the results.
            for testsuite in $(jq '.testsuites[]' build/unit_tests/twister-out/twister.json | tr -d '\t\r\n '); do
              for status in $(echo ${testsuite} | jq '.status'); do
                if [[ "${status}" != "\"passed\"" ]]; then
                  pack_logs
                  exit 1
                fi
              done
            done

            pack_logs
          displayName: Run unit tests

        - task: PublishPipelineArtifact@1
          displayName: 'Publish Unit tests'
          inputs:
            targetPath: '$(Build.ArtifactStagingDirectory)'
            artifact: 'unit_tests_$(System.JobId)'
          condition: always()

  - stage: build_io_bootloader
    displayName: Build IO bootloader
    dependsOn: ztest
    pool:
      name: 'Embedded'
      demands: TM_CAP_YOCTO_BUILD -equals 1

    jobs:
      - job: build_io_bootloader
        timeoutInMinutes: 360
        container:
          image: tmesw.azurecr.io/mcu-builder:latest
          endpoint: tmesw-container-registry

        steps:
        - checkout: self
          clean: false
          persistCredentials: true

        - script: |
            unset ZEPHYR_BASE
            if [[ "$ZEPHYR_REQUIREMENTS" != "$(yq -r .manifest.projects[0].revision mcu-project/west.yml)" ]]; then
                echo "Updating Zephyr python requirements"
                pip3 install --user -r zephyrproject/zephyr/scripts/requirements.txt
            fi

            if ! ./build.py -t io1060 -l; then
              exit 1
            fi

            tar -czf "$(Build.ArtifactStagingDirectory)/io_bootloader_$(Build.BuildNumber).tar.gz" -C build/io1060/bootloader .
          displayName: Build IO bootloader

        - publish: $(Build.ArtifactStagingDirectory)
          artifact: IO Bootloader FW
          displayName: Publish FW

  - stage: build_io
    displayName: Build IO
    dependsOn: ztest
    pool:
      name: 'Embedded'
      demands: TM_CAP_YOCTO_BUILD -equals 1

    jobs:
      - job: build_io
        timeoutInMinutes: 360
        container:
          image: tmesw.azurecr.io/mcu-builder:latest
          endpoint: tmesw-container-registry

        steps:
        - checkout: self
          clean: false
          persistCredentials: true

        - script: |
            unset ZEPHYR_BASE
            if [[ "$ZEPHYR_REQUIREMENTS" != "$(yq -r .manifest.projects[0].revision mcu-project/west.yml)" ]]; then
                echo "Updating Zephyr python requirements"
                pip3 install --user -r zephyrproject/zephyr/scripts/requirements.txt
            fi
            pip3 install --user -I protobuf==3.6.1

            if ! ./build.py -t io1060; then
              echo "Failed to build IO controller"
              exit 1
            fi

            cp build/io1060/app/zephyr/zephyr.signed.bin $(Build.ArtifactStagingDirectory)/zephyr.signed-$(version).bin

            mkdir -p $(Build.ArtifactStagingDirectory)/proto/inner/
            mkdir -p $(Build.ArtifactStagingDirectory)/proto/outer/
            cp -r mcu-project/apps/io/src/message_handlers/proto/. $(Build.ArtifactStagingDirectory)/proto/inner/
            cp mcu-project/modules/message_handler/outer.proto $(Build.ArtifactStagingDirectory)/proto/outer/
            cp -r mcu-project/modules/message_handler/google $(Build.ArtifactStagingDirectory)/proto/outer/
          displayName: Build IO

        - publish: $(Build.ArtifactStagingDirectory)
          artifact: IO MCU FW
          displayName: Publish FW

        - task: UniversalPackages@0
          displayName: Publish .proto to Azure Artifacts
          condition: eq(variables['system.pullrequest.pullrequestid'], '')
          inputs:
            command: publish
            publishDirectory: $(Build.ArtifactStagingDirectory)
            vstsFeedPublish: 'Embedded/io-controller'
            vstsFeedPackagePublish: 'io-tma0005'
            versionOption: custom
            versionPublish: '$(version)'
            packagePublishDescription: 'Publish IO Proto files'

  - stage: build_ble
    displayName: Build BLE
    dependsOn: ztest
    pool:
      name: 'Embedded'
      demands: TM_CAP_YOCTO_BUILD -equals 1

    jobs:
      - job: build_ble
        timeoutInMinutes: 360
        container:
          image: tmesw.azurecr.io/mcu-builder:latest
          endpoint: tmesw-container-registry

        steps:
        - checkout: self
          clean: false
          persistCredentials: true

        - script: |
            unset ZEPHYR_BASE
            if [[ "$ZEPHYR_REQUIREMENTS" != "$(yq -r .manifest.projects[0].revision mcu-project/west.yml)" ]]; then
                echo "Updating Zephyr python requirements"
                pip3 install --user -r zephyrproject/zephyr/scripts/requirements.txt
            fi
            ./build.py -t ble
            tar -czf "$(Build.ArtifactStagingDirectory)/ble_app_$(Build.BuildNumber).tar.gz" -C build/ble/app .
          displayName: Build BLE

        - publish: $(Build.ArtifactStagingDirectory)
          artifact: BLE MCU FW
          displayName: Publish FW

## Test MCU (TM5)
  - stage: smoke_test_mcu_tm5
    displayName: Smoke-testing TM5 MCU
    dependsOn:
      - build_io_bootloader
      - build_io
      - build_ble
    condition: and(succeeded('build_io_bootloader'), succeeded('build_io'), succeeded('build_ble'))
    pool:
      name: Embedded
      demands: TM_CAP_TM5_MCU -equals 1
    jobs:
    - job: smoke_test
      timeoutInMinutes: 45
      displayName: Smoke-testing MCU TM5
      steps:
      - checkout: self
        clean: true
        fetchDepth: 1

      - script: |
          results_folder="$(System.DefaultWorkingDirectory)/pytest/results"
          echo "Results folder: ${results_folder}"
          echo "##vso[task.setvariable variable=results_folder]$results_folder"

          tests_folder="$(System.DefaultWorkingDirectory)/pytest"
          echo "Tests folder: ${tests_folder}"
          echo "##vso[task.setvariable variable=tests_folder]$tests_folder"

          binaries_folder="$(System.DefaultWorkingDirectory)/pytest/binaries"
          echo "Binaries folder: ${binaries_folder}"
          echo "##vso[task.setvariable variable=binaries_folder]$binaries_folder"

          pip_r_folder="$(System.DefaultWorkingDirectory)/docker"
          echo "Binaries folder: ${pip_r_folder}"
          echo "##vso[task.setvariable variable=pip_r_folder]$pip_r_folder"
        displayName: Set Folders Struct

      - script: |
          rm -rf $(results_folder)/*
        displayName: Remove old Test reports

      - script: |
          fw_binary_old=$(ls $(binaries_folder)/*.bin)
          echo "Old FW file: ${fw_binary_old}"
          rm -rf $(binaries_folder)/*
        displayName: Remove old FWs

      - task: DownloadPipelineArtifact@2
        displayName: Download FW
        inputs:
          artifact: IO MCU FW
          path: '$(binaries_folder)/'
          ${{ if eq('nightly', 'todo') }}:
            source: 'specific'
            project: 'Embedded'
            pipeline: 1411
            runVersion: 'latestFromBranch'
            runBranch: 'refs/heads/master'
          ${{ if eq('smoke', 'smoke') }}:
            source: 'current'

      - script: |
          echo "Current Branch: $(Build.SourceBranch)"
        displayName: Current Branch

      - script: |
          file_name=$(ls $(binaries_folder)/*.bin)
          echo "FW binary file: ${file_name}"
          echo "##vso[task.setvariable variable=file_name]$file_name"
        displayName: Get Firmware File

      - script: |
          pytest --version
          python3 -m venv mcu_py_venev
          source mcu_py_venev/bin/activate
          pip3 install -r $(pip_r_folder)/requirements.txt

          echo "Generate environment file env-setup.json"
          jq -n '{
              "device": {
                  "mcu_serial_zephyr": "$(MCU_ZEPHYR_IO_DEVICE)",
                  "mcu_serial_jlink": "$(MCU_SEGGER_JLINK)",
                  "raspi_serial_pico": "$(RASPBERRY_PICO)",
                  "mcu_communication_protocol": "usb",
                  "mcu_interface": "io"
                  },
              "binaries": {
                  "normal": {
                    "file": "$(file_name)",
                    "path": "$(binaries_folder)",
                    "version": "$(version)"
                    },
                  "recovery": {
                    "file": "/home/tm/mcu_binaries/zephyr.signed.bin",
                    "path": "/home/tm/mcu_binaries",
                    "version": ""
                    },
                  "bootloader": {
                    "file": "/home/tm/mcu_binaries/zephyr.bin",
                    "path": "/home/tm/mcu_binaries",
                    "version": ""
                    }
                  },
              "paths": {
                  "root_path": "$(System.DefaultWorkingDirectory)",
                  "test_path": "$(tests_folder)",
                  "results_path": "$(results_folder)",
                  "flashloader_path": "$(TOOL_FLASHLOADER_PATH)"
                  },
              "dev_mode": {
                  "skip_flash": false,
                  "skip_recovery": false
                  }
              }' > env-setup.json
          cat env-setup.json| jq empty; echo "Validate env file [ok==0 ; nok==1]: $?"
          if [ $? != 0 ]; then
              exit $?
          fi

          echo "Start serial tool to collect prints form segger port"
          mkdir $(results_folder)
          python3 pytest/libraries/print_collector.py -s $(MCU_SEGGER_JLINK) -p $(results_folder) -f segger_serial.log &

          echo "Start testing $(version)"
          pytest $(tests_folder) \
            --junitxml $(results_folder)/xunit.xml --html $(results_folder)/report.html \
            --envfile env-setup.json \
            -s -v
          status=$?
          echo "Test end status: ${status}"

          echo "Send SIGINT signal to serial tool in 3 secs"
          python3 -c "from time import sleep; sleep(3)"
          kill -SIGINT `cat $(results_folder)/tmp_pid`
          echo "Serial tool killed [ok==0 ; nok==1]: $?"
          echo "Wait 5 sec serial tool to close all files"
          python3 -c "from time import sleep; sleep(5)"

          exit $status

        workingDirectory: '$(System.DefaultWorkingDirectory)/'
        displayName: Test fw version $(version)

      - task: PublishPipelineArtifact@1
        displayName: 'Publish test Reports'
        inputs:
          targetPath: '$(results_folder)/'
          artifact: 'IO MCU TEST REPORT'
        condition: always()

  - stage: gen_doxy_documentation
    displayName: "Generating Doxygen documentation"
    dependsOn: smoke_test_mcu_tm5
    pool:
      vmImage: 'ubuntu-20.04'
    jobs:
    - job:
      displayName: Doxygen
      steps:
      - checkout: self
        clean: false
        persistCredentials: true

      - script: |
          sudo apt install doxygen graphviz
        displayName: Installing Doxygen prerequisites

      - script: |
          RET_CODE=0
          echo "Generating Doxygen documentation."
          ./build.py -d io
          if [ $? != 0 ]
          then
            echo "Couldn't generate IO docs"
            RET_CODE=1
          fi

          ./build.py -d ble
          if [ $? != 0 ]
          then
            echo "Couldn't generate BLE docs"
            RET_CODE=1
          fi

          ./build.py -d modules
          if [ $? != 0 ]
          then
            echo "Couldn't generate Modules docs"
            RET_CODE=1
          fi

          if [ $RET_CODE != 0 ]
          then
            exit $RET_CODE
          else
            echo "Compressing html"
            zip -r build/Doxygen_IO/mcu_io_docs.zip build/Doxygen_IO/html
            zip -r build/Doxygen_BLE/mcu_ble_docs.zip build/Doxygen_BLE/html
            zip -r build/Doxygen_Modules/mcu_modules_docs.zip build/Doxygen_Modules/html
          fi
        displayName: Generating doxygen documentation

      - task: CopyFiles@2
        displayName: 'Copying build files to Artifacts'
        inputs:
          contents: |
            build/Doxygen_IO/mcu_io_docs.zip
            build/Doxygen_IO/DoxygenWarningLog_IO.txt
            build/Doxygen_BLE/mcu_ble_docs.zip
            build/Doxygen_BLE/DoxygenWarningLog_BLE.txt
            build/Doxygen_Modules/mcu_modules_docs.zip
            build/Doxygen_Modules/DoxygenWarningLog_Modules.txt
          targetFolder: '$(Build.ArtifactStagingDirectory)'

      - publish: '$(Build.ArtifactStagingDirectory)'
        displayName: Publishing documentation artifacts
        artifact: drop